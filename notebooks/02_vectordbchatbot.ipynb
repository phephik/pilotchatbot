{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cBPbA5zPXv-a"
      },
      "source": [
        "### 01_load2vectordb\n",
        "\n",
        "#### Overview\n",
        "This script is part of a pipeline that processes PDF documents and stores their data in a vector database for easy retrieval and analysis. The script performs the following key steps:\n",
        "\n",
        "#### Use Cases\n",
        "- Enhance search capabilities within a document database.\n",
        "- Enable similarity-based document analysis.\n",
        "- Facilitate advanced text analytics in a variety of domains.\n",
        "\n",
        "##### 1. Data Loading from PDFs\n",
        "##### 2. Text Splitting\n",
        "##### 3. Embedding Creation\n",
        "##### 4. Context-based chatbot\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "from dotenv import load_dotenv\n",
        "import os\n",
        "from langchain.chains import create_extraction_chain\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.document_loaders import TextLoader\n",
        "from langchain.docstore.document import Document\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from langchain.document_loaders import PyPDFLoader\n",
        "import tiktoken\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "import re\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "import PyPDF2\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p9Yb6l1JYAKv"
      },
      "source": [
        "##### Load my api key"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load the .env file\n",
        "load_dotenv()\n",
        "\n",
        "# Accessing variables\n",
        "myapikey = os.getenv('OPENAI_API_KEY')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KNZj-tm1X3Gr"
      },
      "source": [
        "##### 1. Data Loading from PDFs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uoV3FOlYIxyl",
        "outputId": "6d44e016-a7ce-4735-b015-d486b0d881dc"
      },
      "outputs": [],
      "source": [
        "# Define the folder path to the PDF files\n",
        "folder_path = '../data/cz_vfr_manual/'\n",
        "\n",
        "# Get a list of PDF files in the directory\n",
        "pdf_files = [f for f in os.listdir(folder_path) if f.endswith('.pdf')]\n",
        "pdf_paths = [os.path.join(folder_path, file) for file in pdf_files]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### 2. Text Splitting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "tokenizer_name = tiktoken.encoding_for_model('gpt-4')\n",
        "tokenizer_name.name\n",
        "\n",
        "# create the length function\n",
        "def tiktoken_len(text):\n",
        "    tokens = tokenizer_name.encode(\n",
        "        text,\n",
        "        disallowed_special=()\n",
        "    )\n",
        "    return len(tokens)\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=256,\n",
        "    chunk_overlap=64,\n",
        "    length_function=tiktoken_len,\n",
        "    separators=[\".\"],\n",
        "    is_separator_regex=False,\n",
        ")\n",
        "\n",
        "def extract_cz_tags_from_filename(filename):\n",
        "    # Extract the first occurrence of ICAO code from the filename\n",
        "    match = re.search(r'lk[a-z]{2,6}', filename)\n",
        "    \n",
        "    # Return the found code in uppercase if there's a match, otherwise return None\n",
        "    return match.group().upper() if match else None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "OpenAI Chat model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "llm = ChatOpenAI(openai_api_key=myapikey, temperature=0, model_name=\"gpt-4\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "OpenAI Embeddings model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "model_name = 'text-embedding-ada-002'\n",
        "\n",
        "embed = OpenAIEmbeddings(\n",
        "    model=model_name,\n",
        "    openai_api_key=myapikey\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Loading PDF to chunks enhanced with ICAO code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9yB4EyI9htca",
        "outputId": "fb2b46f1-fdda-493f-b6a3-89cd1c83ec60"
      },
      "outputs": [],
      "source": [
        "chunked_texts_with_tags = []\n",
        "# Iterate over each PDF file\n",
        "for path in pdf_paths:\n",
        "    # Extract the filename from the path\n",
        "    filename = os.path.basename(path)\n",
        "\n",
        "    # Extract tags from the filename\n",
        "    pdf_tags = extract_cz_tags_from_filename(filename)\n",
        "    #print(pdf_tags)\n",
        "    # Open and read the PDF file\n",
        "    pdf_reader = PyPDF2.PdfReader(path)\n",
        "    full_text = f\"Document: {filename}\\n\"  # Start with the filename\n",
        "\n",
        "    for page in pdf_reader.pages:\n",
        "        # if less than 200 char then skip\n",
        "        if len(page.extract_text()) < 200:\n",
        "            continue\n",
        "        else:\n",
        "            page_text = page.extract_text()\n",
        "            if page_text:  # Check if text extraction is successful\n",
        "                page_text = page_text.replace('\\n', '')\n",
        "                full_text += page_text\n",
        "            else:\n",
        "                full_text += f\"[No text extracted from this page]\\n\"\n",
        "            \n",
        "            chunks = text_splitter.split_text(full_text)\n",
        "            # Add tags to each chunk\n",
        "            for chunk in chunks:\n",
        "                chunk_with_tags = f\"{(pdf_tags)}, {chunk}\"\n",
        "                chunked_texts_with_tags.append(chunk_with_tags)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### 3. Embedding Creation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain.vectorstores import Chroma\n",
        "vectorstore = Chroma(embedding_function=OpenAIEmbeddings(), persist_directory=\"../data/vectordb/\")\n",
        "db2 = vectorstore.from_texts(chunked_texts_with_tags, embed, persist_directory=\"../data/vectordb/\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### 4. Context-based chatbot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " The altitude of Letnany Airport is 912 ft / 278 m above mean sea level.\n"
          ]
        }
      ],
      "source": [
        "from langchain.chains import RetrievalQA\n",
        "from langchain.llms import OpenAI\n",
        "\n",
        "qa_chain = RetrievalQA.from_chain_type(\n",
        "    llm=OpenAI(),\n",
        "    retriever=db2.as_retriever(search_kwargs={'k': 5}),\n",
        "    return_source_documents=True\n",
        ")\n",
        "\n",
        "# we can now execute queries against our Q&A chain\n",
        "result = qa_chain({'query': 'Altitude of Letnany Aiport'})\n",
        "print(result['result'])"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
